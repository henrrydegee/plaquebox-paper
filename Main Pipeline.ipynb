{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Visualization - Prediction Confidence Heatmaps\n",
    "\n",
    "A sliding window approach was applied on the whole slide images (WSIs) with the trained CNN model to generate confidence heatmaps. \n",
    "\n",
    "The WSIs were tiled into 1536 x 1536 images patches in the prepocessing steps. A sliding window approached was applied on evey image patch of a WSI. At each time, the CNN model took a 256x256 pixels region as input, forward propagated and generated a prediction score for cored plaque, diffuse plaque and CAA respectively. By systematically sliding the input region across the entire 1536 x 1536 image patch, the prediction scores were saved and ploted as prediction confidence heatmap for this patch. The heatmap for the WSI was obtained by doing this on all image patches of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Pre-Processing for Inference\n",
    "\n",
    "Reinhard Normalization was applied to the WSI, followed by tiling into 1536 x 1536 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvips as Vips\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import vips_utils, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "WSI_DIR = 'data/wsi/'\n",
    "SAVE_DIR = 'data/norm_tiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_imagename = 'NA3777-02_AB.svs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NA3777-02_AB.svs', 'NA4077-02_AB.svs']\n"
     ]
    }
   ],
   "source": [
    "wsi_slides = os.listdir(WSI_DIR)\n",
    "imagenames = sorted(wsi_slides)\n",
    "print(imagenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NA3777-02_AB', 'NA4077-02_AB']\n"
     ]
    }
   ],
   "source": [
    "print([os.path.splitext(img)[0] for img in imagenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 41s, sys: 25.4 s, total: 45min 6s\n",
      "Wall time: 13min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load reference image, fit Reinhard normalizer\n",
    "ref_image = Vips.Image.new_from_file(WSI_DIR + ref_imagename, level=0)\n",
    "\n",
    "normalizer = normalize.Reinhard()\n",
    "normalizer.fit(ref_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Image: data/wsi/NA3777-02_AB.svs\n",
      "data/norm_tiles/NA3777-02_AB.svs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [02:54<02:54, 174.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Image: data/wsi/NA4077-02_AB.svs\n",
      "data/norm_tiles/NA4077-02_AB.svs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [24:21<00:00, 730.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# Perform Preprocessing: Reinhard Normalization\n",
    "stats_dict = {}\n",
    "for imagename in tqdm(imagenames[:]):\n",
    "    \n",
    "    vips_img = Vips.Image.new_from_file(WSI_DIR + imagename, level=0)\n",
    "    print(\"Loaded Image: \" + WSI_DIR + imagename)\n",
    "    \n",
    "    out = normalizer.transform(vips_img)\n",
    "#     out.filename = vips_img.filename\n",
    "    vips_utils.save_and_tile(out, os.path.splitext(imagename)[0] \\\n",
    "                             , SAVE_DIR)\n",
    "    stats_dict[imagename] = normalizer.image_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                              means  \\\n",
      "NA3777-02_AB.svs  (84.87683078374981, 1.8838342760860847, 6.5489...   \n",
      "NA4077-02_AB.svs  (91.31315579601524, 0.7904653477819064, 0.5140...   \n",
      "\n",
      "                                                               stds  \n",
      "NA3777-02_AB.svs  (14.24781939673603, 3.8341760541297303, 8.0651...  \n",
      "NA4077-02_AB.svs  (9.03693714170581, 2.3375789731693617, 3.51060...  \n"
     ]
    }
   ],
   "source": [
    "# Some Statistics about WSI Slide\n",
    "import pandas as pd\n",
    "stats = pd.DataFrame(stats_dict)\n",
    "stats = stats.transpose()\n",
    "stats.columns = 'means', 'stds'\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Main Pipeline for Inference\n",
    "\n",
    "Estimation time per WSI slide: 4.5 hrs on Titan XP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0 0.5.0\n"
     ]
    }
   ],
   "source": [
    "import time, os, glob\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(123456789)\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "print(torch.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR  = 'data/norm_tiles/'\n",
    "\n",
    "# Plaque Detection\n",
    "MODEL_PLAQ_DIR = 'models/CNN_model_parameters.pkl'\n",
    "SAVE_PLAQ_DIR = 'data/outputs/heatmaps/'\n",
    "\n",
    "# Brainseg\n",
    "MODEL_SEG_DIR = 'models/ResNet18_19.pkl'\n",
    "SAVE_IMG_DIR = 'data/brainseg/images/'\n",
    "SAVE_NP_DIR = 'data/brainseg/numpy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_PLAQ_DIR):\n",
    "        os.makedirs(SAVE_PLAQ_DIR)\n",
    "        \n",
    "if not os.path.exists(SAVE_IMG_DIR):\n",
    "        os.makedirs(SAVE_IMG_DIR)\n",
    "        \n",
    "if not os.path.exists(SAVE_NP_DIR):\n",
    "        os.makedirs(SAVE_NP_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 1536\n",
    "stride = 16\n",
    "batch_size = 32 \n",
    "num_workers = 16\n",
    "# Note: BrainSeg can only work in \n",
    "# batch_size of 1, 8, 16, 32, 96\n",
    "# in the way it is coded (not 64)\n",
    "# To check: (96/batch_size) == int\n",
    "\n",
    "# The values between Plaquebox & Brainseg are about the same\n",
    "# norm = np.load('utils/normalization.npy', allow_pickle=True).item() # plaquebox\n",
    "# normalize = transforms.Normalize(norm['mean'], norm['std'])\n",
    "# print(normalize)\n",
    "norm = np.load('norm_brainseg/normalization.npy', allow_pickle=True).item() # brainseg\n",
    "normalize = transforms.Normalize(norm['mean'], norm['std'])\n",
    "# print(normalize)\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Retrieve Files\n",
    "filenames = glob.glob(IMG_DIR + '*')\n",
    "filenames = [filename.split('/')[-1] for filename in filenames]\n",
    "filenames = sorted(filenames)\n",
    "# print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HeatmapDataset(Dataset):\n",
    "    def __init__(self, tile_dir, row, col, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tile_dir (string): path to the folder where tiles are\n",
    "            row (int): row index of the tile being operated\n",
    "            col (int): column index of the tile being operated\n",
    "            stride: stride of sliding \n",
    "        \"\"\"\n",
    "        self.tile_size = 256\n",
    "        self.img_size = 1536\n",
    "        self.stride = stride\n",
    "        padding = 128\n",
    "        large_img = torch.ones(3, 3*self.img_size, 3*self.img_size)\n",
    "        \n",
    "        for i in [-1,0,1]:\n",
    "            for j in [-1,0,1]:\n",
    "                img_path = tile_dir+'/'+str(row+i)+'/'+str(col+j)+'.jpg'\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    img = transforms.ToTensor()(img) \n",
    "                except:\n",
    "                    img = torch.ones(3,self.img_size, self.img_size)\n",
    "                \n",
    "                large_img[:, (i+1)*self.img_size:(i+2)*self.img_size,(j+1)*self.img_size:(j+2)*self.img_size] = img\n",
    "        \n",
    "        large_img = normalize(large_img)\n",
    "        \n",
    "        self.padding_img = large_img[:,self.img_size-padding:2*self.img_size+padding, self.img_size-padding:2*self.img_size+padding]\n",
    "        self.len = (self.img_size//self.stride)**2\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        row = (index*self.stride // self.img_size)*self.stride\n",
    "        col = (index*self.stride % self.img_size)\n",
    "\n",
    "        img = self.padding_img[:, row:row+self.tile_size, col:col+self.tile_size]        \n",
    "    \n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, fc_nodes=512, num_classes=3, dropout=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    " \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.parallel.data_parallel.DataParallel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Check GPU:\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# instatiate the model\n",
    "plaq_model = torch.load(MODEL_PLAQ_DIR, map_location=lambda storage, loc: storage)\n",
    "seg_model = torch.load(MODEL_SEG_DIR, map_location=lambda storage, loc: storage)\n",
    "\n",
    "if use_gpu:\n",
    "    seg_model = seg_model.cuda() # Segmentation\n",
    "    plaq_model = plaq_model.module.cuda() # Plaquebox-paper\n",
    "else:\n",
    "    seg_model = seg_model\n",
    "    plaq_model = plaq_model.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveBrainSegImage(nums, save_dir) :\n",
    "    \"\"\"\n",
    "    Converts 2D array with {0,1,2} into RGB\n",
    "     to determine different segmentation areas\n",
    "     and saves image at given directory\n",
    "    \n",
    "    Input:\n",
    "       nums: 2D-NumPy Array containing classification\n",
    "       save_dir: string indicating save location\n",
    "    \"\"\" \n",
    "    \n",
    "    nums = np.repeat(nums[:,:, np.newaxis], 3, axis=2)\n",
    "    \n",
    "    # nums[:,:,0] = RED, nums[:,:,1] = Green, nums[:,:,2] = Blue\n",
    "    idx_1 = np.where(nums[:,:,0] == 1)  # Index of label 1 (WM)\n",
    "    idx_2 = np.where(nums[:,:,0] == 2)  # Index of label 2 (GM)\n",
    "\n",
    "    # For label 0, leave as black color\n",
    "    # For label 1, set to yellow color: R255G255B0 (WM)\n",
    "    nums[:,:,0].flat[np.ravel_multi_index(idx_1, nums[:,:,0].shape)] = 255\n",
    "    nums[:,:,1].flat[np.ravel_multi_index(idx_1, nums[:,:,1].shape)] = 255\n",
    "    nums[:,:,2].flat[np.ravel_multi_index(idx_1, nums[:,:,2].shape)] = 0\n",
    "    # For label 2, set to cyan color: R0G255B255 (GM)\n",
    "    nums[:,:,0].flat[np.ravel_multi_index(idx_2, nums[:,:,0].shape)] = 0\n",
    "    nums[:,:,1].flat[np.ravel_multi_index(idx_2, nums[:,:,1].shape)] = 255\n",
    "    nums[:,:,2].flat[np.ravel_multi_index(idx_2, nums[:,:,2].shape)] = 255\n",
    "\n",
    "    nums = nums.astype(np.uint8) # PIL save only accepts uint8 {0,..,255}\n",
    "    save_img = Image.fromarray(nums, 'RGB')\n",
    "    save_img.save(save_dir)\n",
    "    print(\"Saved at: \" + save_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing:  NA3777-02_AB.svs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 31/31 [4:28:52<00:00, 520.39s/it]  \n",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/brainseg/images/NA3777-02_AB.svs.png\n",
      "Time to process NA3777-02_AB.svs:  16133.922263165936 sec\n",
      "Now processing:  NA4077-02_AB.svs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [5:58:17<00:00, 693.48s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/brainseg/images/NA4077-02_AB.svs.png\n",
      "Time to process NA4077-02_AB.svs:  21500.137213384733 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Inference Loop:\n",
    "\n",
    "for filename in filenames[:] :\n",
    "    print(\"Now processing: \", filename)\n",
    "    \n",
    "    # Retrieve Files\n",
    "    TILE_DIR = IMG_DIR+'{}/0/'.format(filename)\n",
    "\n",
    "    imgs = []\n",
    "    for target in sorted(os.listdir(TILE_DIR)):\n",
    "        d = os.path.join(TILE_DIR, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if fname.endswith('.jpg'):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    imgs.append(path)\n",
    "\n",
    "    rows = [int(image.split('/')[-2]) for image in imgs]\n",
    "    row_nums = max(rows) + 1\n",
    "    cols = [int(image.split('/')[-1].split('.')[0]) for image in imgs]\n",
    "    col_nums = max(cols) +1    \n",
    "    \n",
    "    # Initialize outputs accordingly:\n",
    "    heatmap_res = img_size // stride\n",
    "    plaque_output = np.zeros((3, heatmap_res*row_nums, heatmap_res*col_nums))\n",
    "    seg_output = np.zeros((heatmap_res*row_nums, heatmap_res*col_nums), dtype=np.uint8)\n",
    "\n",
    "    seg_model.train(False)  # Set model to evaluate mode\n",
    "    plaq_model.train(False)\n",
    "    \n",
    "    start_time = time.perf_counter() # To evaluate Time taken per inference\n",
    "\n",
    "    for row in tqdm(range(row_nums)):\n",
    "        for col in range(col_nums):\n",
    "\n",
    "            image_datasets = HeatmapDataset(TILE_DIR, row, col, stride=stride)\n",
    "            dataloader = torch.utils.data.DataLoader(image_datasets, batch_size=batch_size,\n",
    "                                                 shuffle=False, num_workers=num_workers)\n",
    "            \n",
    "            # From Plaque-Detection:\n",
    "            running_plaques = torch.Tensor(0)\n",
    "            # For Stride 32 (BrainSeg):\n",
    "            running_seg = torch.zeros((32), dtype=torch.uint8)\n",
    "            output_class = np.zeros((heatmap_res, heatmap_res), dtype=np.uint8)\n",
    "            \n",
    "            for idx, data in enumerate(dataloader):\n",
    "                # get the inputs\n",
    "                inputs = data\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda(), volatile=True)\n",
    "                    \n",
    "                    # forward (Plaque Detection) :\n",
    "                    outputs = plaq_model(inputs)\n",
    "                    preds = F.sigmoid(outputs) # Posibility for each class = [0,1]\n",
    "                    preds = preds.data.cpu()\n",
    "                    running_plaques = torch.cat([running_plaques, preds])\n",
    "                    \n",
    "                    # forward (BrainSeg) :\n",
    "                    predict = seg_model(inputs)\n",
    "                    _, indices = torch.max(predict.data, 1) # indices = 0:Background, 1:WM, 2:GM\n",
    "                    indices = indices.type(torch.uint8)\n",
    "                    running_seg =  indices.data.cpu()\n",
    "\n",
    "                    # For Stride 32 (BrainSeg) :\n",
    "                    i = (idx // (heatmap_res//batch_size))\n",
    "                    j = (idx % (heatmap_res//batch_size))\n",
    "                    output_class[i,j*batch_size:(j+1)*batch_size] = running_seg\n",
    "            \n",
    "            # Final Outputs of Brain Segmentation\n",
    "            seg_output[row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = output_class\n",
    "            \n",
    "            # Final Outputs of Plaque Detection:\n",
    "            cored = np.asarray(running_plaques[:,0]).reshape(img_size//stride,img_size//stride)\n",
    "            diffuse = np.asarray(running_plaques[:,1]).reshape(img_size//stride,img_size//stride)\n",
    "            caa = np.asarray(running_plaques[:,2]).reshape(img_size//stride,img_size//stride)\n",
    "            \n",
    "            plaque_output[0, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = cored\n",
    "            plaque_output[1, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = diffuse\n",
    "            plaque_output[2, row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = caa\n",
    "\n",
    "            seg_output[row*heatmap_res:(row+1)*heatmap_res, col*heatmap_res:(col+1)*heatmap_res] = output_class\n",
    "\n",
    "    # Saving Confidence=[0,1] for Plaque Detection\n",
    "    np.save(SAVE_PLAQ_DIR+filename, plaque_output)\n",
    "    \n",
    "    # Saving BrainSeg Classification={0,1,2}\n",
    "    np.save(SAVE_NP_DIR+filename, seg_output)\n",
    "    saveBrainSegImage(seg_output, \\\n",
    "                      SAVE_IMG_DIR + filename + '.png')\n",
    "    \n",
    "    # Time Statistics for Inference\n",
    "    end_time = time.perf_counter()\n",
    "    print(\"Time to process \" \\\n",
    "          + filename \\\n",
    "          + \": \", end_time-start_time, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(final_output) :\n",
    "    \"\"\"\n",
    "    Plots Confidence Heatmap of Plaques = [0,1]\n",
    "    \n",
    "    Inputs:\n",
    "        final_output (NumPy array of \n",
    "        3*img_height*height_width) :\n",
    "            Contains Plaque Confidence with each axis\n",
    "            representing different types of plaque\n",
    "            \n",
    "    Outputs:\n",
    "        Subplots containing Plaque Confidences\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(45,15))\n",
    "\n",
    "    ax = fig.add_subplot(311)\n",
    "\n",
    "    im = ax.imshow(final_output[0], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "    ax = fig.add_subplot(312)\n",
    "\n",
    "    im = ax.imshow(final_output[1], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "    ax = fig.add_subplot(313)\n",
    "\n",
    "    im = ax.imshow(final_output[2], cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Post-processing and Counting Plaques at each Segmentation Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob, os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from scipy import stats\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def saveBrainSegImage(nums, save_dir) :\n",
    "    \"\"\"\n",
    "    Converts 2D array with {0,1,2} into RGB\n",
    "     to determine different segmentation areas\n",
    "     and saves image at given directory\n",
    "    \n",
    "    Input:\n",
    "       nums: 2D-NumPy Array containing classification\n",
    "       save_dir: string indicating save location\n",
    "    \"\"\" \n",
    "    \n",
    "    nums = np.repeat(nums[:,:, np.newaxis], 3, axis=2)\n",
    "    \n",
    "    # nums[:,:,0] = RED, nums[:,:,1] = Green, nums[:,:,2] = Blue\n",
    "    idx_1 = np.where(nums[:,:,0] == 1)  # Index of label 1 (WM)\n",
    "    idx_2 = np.where(nums[:,:,0] == 2)  # Index of label 2 (GM)\n",
    "\n",
    "    # For label 0, leave as black color\n",
    "    # For label 1, set to yellow color: R255G255B0 (WM)\n",
    "    nums[:,:,0].flat[np.ravel_multi_index(idx_1, nums[:,:,0].shape)] = 255\n",
    "    nums[:,:,1].flat[np.ravel_multi_index(idx_1, nums[:,:,1].shape)] = 255\n",
    "    nums[:,:,2].flat[np.ravel_multi_index(idx_1, nums[:,:,2].shape)] = 0\n",
    "    # For label 2, set to cyan color: R0G255B255 (GM)\n",
    "    nums[:,:,0].flat[np.ravel_multi_index(idx_2, nums[:,:,0].shape)] = 0\n",
    "    nums[:,:,1].flat[np.ravel_multi_index(idx_2, nums[:,:,1].shape)] = 255\n",
    "    nums[:,:,2].flat[np.ravel_multi_index(idx_2, nums[:,:,2].shape)] = 255\n",
    "\n",
    "    nums = nums.astype(np.uint8) # PIL save only accepts uint8 {0,..,255}\n",
    "    save_img = Image.fromarray(nums, 'RGB')\n",
    "    save_img.save(save_dir)\n",
    "    print(\"Saved at: \" + save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage import morphology, measure\n",
    "# import lxml.etree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Post-Processing BrainSeg - Jeff, Kolin, Wenda\n",
    "def method_6(mask_img: \"Image\", down_factor=4) -> \"NDArray[np.uint8]\":\n",
    "    \"\"\"Downsample => Area_opening (Remove local maxima) =>\n",
    "    Swap index of GM and WM => Area_opening => Swap index back =>\n",
    "    Area_closing => Morphological opening => Upsample\"\"\"\n",
    "    # pylint: disable=invalid-name\n",
    "    def swap_GM_WM(arr):\n",
    "        \"\"\"Swap GM and WM in arr (swaps index 1 and index 2)\"\"\"\n",
    "        arr_1 = (arr == 1)\n",
    "        arr[arr == 2] = 1\n",
    "        arr[arr_1] = 2\n",
    "        del arr_1\n",
    "        return arr\n",
    "    # pylint: enable=invalid-name\n",
    "\n",
    "    mask_img = Image.fromarray(mask_img)\n",
    "    width, height = mask_img.width, mask_img.height\n",
    "    area_threshold_prop = 0.05\n",
    "    area_threshold = int(area_threshold_prop * width * height // down_factor**2)\n",
    "\n",
    "    # Downsample the image\n",
    "    mask_arr = np.array(\n",
    "        mask_img.resize((width // down_factor, height // down_factor), Image.NEAREST))\n",
    "    del mask_img\n",
    "    print('Finish downsampling')\n",
    "\n",
    "    # Apply area_opening to remove local maxima with area < 20000 px\n",
    "    mask_arr = morphology.area_opening(mask_arr, area_threshold=320000 // down_factor**2)\n",
    "    print('Finish area_opening #1')\n",
    "\n",
    "    # Swap index of GM and WM\n",
    "    mask_arr = swap_GM_WM(mask_arr)\n",
    "    print('Finish swapping index')\n",
    "\n",
    "    # Apply area_opening to remove local maxima with area < 20000 px\n",
    "    mask_arr = morphology.area_opening(mask_arr, area_threshold=320000 // down_factor**2)\n",
    "    print('Finish area_opening #2')\n",
    "\n",
    "    # Swap index back\n",
    "    mask_arr = swap_GM_WM(mask_arr)\n",
    "    print('Finish swapping index back')\n",
    "\n",
    "    # Apply area_closing to remove local minima with area < 12500 px\n",
    "    mask_arr = morphology.area_closing(mask_arr, area_threshold=200000 // down_factor**2)\n",
    "    print('Finish area_closing')\n",
    "\n",
    "    # Apply remove_small_objects to remove tissue residue with area < 0.05 * width * height\n",
    "    tissue_arr = morphology.remove_small_objects(mask_arr > 0, min_size=area_threshold,\n",
    "                                                 connectivity=2)\n",
    "    mask_arr[np.invert(tissue_arr)] = 0\n",
    "    del tissue_arr\n",
    "    print('Finish remove_small_objects')\n",
    "\n",
    "    # Apply opening with disk-shaped kernel (r=8) to smooth boundary\n",
    "    mask_arr = morphology.opening(mask_arr, selem=morphology.disk(radius=32 // down_factor))\n",
    "    print('Finish morphological opening')\n",
    "\n",
    "    # Upsample the output\n",
    "    mask_arr = np.array(Image.fromarray(mask_arr).resize((width, height), Image.NEAREST))\n",
    "    print('Finish upsampling')\n",
    "\n",
    "    return mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plaque-counting Directories\n",
    "CSV_DIR = 'data/outputs/CNNscore/WSI_CERAD_AREA.csv'\n",
    "HEATMAP_DIR = 'data/outputs/heatmaps/'\n",
    "SAVE_DIR = 'data/outputs/CNNscore/'\n",
    "\n",
    "# BrainSeg Post-processing Directories\n",
    "BRAINSEG_NP_PRE_DIR = 'data/brainseg/numpy/'\n",
    "POST_IMG_DIR = 'data/postprocess/images/'\n",
    "POST_NP_DIR = 'data/postprocess/numpy/'\n",
    "\n",
    "# Counted Plaques Save Directories\n",
    "SAVE_IMG_DIR = 'data/outputs/masked_plaque/images/'\n",
    "SAVE_NP_DIR = 'data/outputs/masked_plaque/numpy/'\n",
    "# print(os.listdir(BRAINSEG_NP_PRE_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NA3777-02_AB', 'NA4077-02_AB', 'NA4092-02_AB', 'NA4107-02_AB', 'NA4160-02_AB', 'NA4195-02_AB', 'NA4256-02_AB', 'NA4299-02_AB', 'NA4391-02_AB', 'NA4450-02_AB', 'NA4463-02_AB', 'NA4471-02_AB', 'NA4553-02_AB', 'NA4626-02_AB', 'NA4672-02_AB', 'NA4675-02_AB', 'NA4691-02_AB', 'NA4695-02_AB']\n"
     ]
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(BRAINSEG_NP_PRE_DIR))\n",
    "filenames = [os.path.splitext(file)[0] for file in filenames]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: data/brainseg/numpy/NA3777-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1/18 [00:04<01:16,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA3777-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4077-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2/18 [00:10<01:24,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4077-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4092-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 3/18 [00:15<01:20,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4092-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4107-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 4/18 [00:20<01:09,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4107-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4160-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 5/18 [00:24<01:01,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4160-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4195-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 6/18 [00:28<00:53,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4195-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4256-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 7/18 [00:33<00:52,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4256-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4299-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 8/18 [00:38<00:46,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4299-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4391-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 9/18 [00:42<00:40,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4391-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4450-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 10/18 [00:47<00:36,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4450-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4463-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 11/18 [00:51<00:32,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4463-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4471-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 12/18 [00:57<00:29,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4471-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4553-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 13/18 [01:02<00:25,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4553-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4626-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 14/18 [01:06<00:18,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4626-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4672-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 15/18 [01:09<00:12,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4672-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4675-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 16/18 [01:14<00:08,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4675-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4691-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 17/18 [01:18<00:04,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4691-02_AB.png\n",
      "Loading: data/brainseg/numpy/NA4695-02_AB.npy\n",
      "Finish downsampling\n",
      "Finish area_opening #1\n",
      "Finish swapping index\n",
      "Finish area_opening #2\n",
      "Finish swapping index back\n",
      "Finish area_closing\n",
      "Finish remove_small_objects\n",
      "Finish morphological opening\n",
      "Finish upsampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [01:22<00:00,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/postprocess/images/NA4695-02_AB.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Post-process BrainSeg\n",
    "for filename in tqdm(filenames) :\n",
    "    fileLoc = BRAINSEG_NP_PRE_DIR + filename + \".npy\"\n",
    "    print(\"Loading: \" + fileLoc)\n",
    "    seg_pic = np.load(fileLoc)\n",
    "    processed = method_6(seg_pic)\n",
    "    np.save(POST_NP_DIR+filename, processed)\n",
    "    saveBrainSegImage(processed, \\\n",
    "                      POST_IMG_DIR + filename + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UserWarning: The argument 'neighbors' is deprecated and will be removed in scikit-image 0.18,\n",
    "# use 'connectivity' instead. For neighbors=8, use connectivity=2\n",
    "#   This is separate from the ipykernel package so we can avoid doing imports until\n",
    "\n",
    "# Post-Processing to count Plaques\n",
    "def count_blobs(mask,\n",
    "               threshold=1500):\n",
    "#     labels = measure.label(mask, neighbors=8, background=0)\n",
    "    labels = measure.label(mask, connectivity=2, background=0)\n",
    "    img_mask = np.zeros(mask.shape, dtype='uint8')\n",
    "    labeled_mask = np.zeros(mask.shape, dtype='uint16')\n",
    "    sizes = []\n",
    "    locations = []\n",
    "    \n",
    "    # loop over the unique components\n",
    "    for label in np.unique(labels):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask and count the\n",
    "        # number of pixels \n",
    "        labelMask = np.zeros(mask.shape, dtype=\"uint8\")\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(labelMask)\n",
    "        \n",
    "        # if the number of pixels in the component is sufficiently\n",
    "        # large, then add it to our mask of \"large blobs\"\n",
    "        if numPixels > threshold:\n",
    "            sizes.append(numPixels)\n",
    "            img_mask = cv2.add(img_mask, labelMask)\n",
    "            \n",
    "            # Save confirmed unique location of plaque\n",
    "            labeled_mask[labels==label] = label\n",
    "\n",
    "    return sizes, img_mask, labeled_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "def plot_mask(mask_array) :\n",
    "    \"\"\"\n",
    "    Plots Post-processed detected Plaques\n",
    "    \n",
    "    Inputs:\n",
    "        mask_array = img_mask from count_blobs()'s output\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(45,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    im = ax.imshow(mask_array, cmap=plt.cm.get_cmap('viridis', 20), vmin=0, vmax=1)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im, cax=cax, ticks=[0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "def saveMask(mask_array, save_dir) :\n",
    "    \n",
    "    mask_array = np.repeat(mask_array[:,:, np.newaxis], 3, axis=2)\n",
    "    \n",
    "    # mask_array[:,:,0] = RED, mask_array[:,:,1] = Green, mask_array[:,:,2] = Blue\n",
    "    idx = np.where(mask_array[:,:,0] == 255)  # Index of label 1 (WM)\n",
    "\n",
    "    # For label 0, leave as black color\n",
    "    # For label 1, set to cyan color: R0G255B255\n",
    "    mask_array[:,:,0].flat[np.ravel_multi_index(idx, mask_array[:,:,0].shape)] = 0\n",
    "    mask_array[:,:,1].flat[np.ravel_multi_index(idx, mask_array[:,:,1].shape)] = 255\n",
    "    mask_array[:,:,2].flat[np.ravel_multi_index(idx, mask_array[:,:,2].shape)] = 255\n",
    "\n",
    "    mask_array = mask_array.astype(np.uint8) # PIL save only accepts uint8 {0,..,255}\n",
    "    save_img = Image.fromarray(mask_array, 'RGB')\n",
    "    save_img.save(save_dir)\n",
    "    print(\"Saved at: \" + save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import hsv2rgb\n",
    "from PIL import Image\n",
    "\n",
    "def saveUniqueMaskImage(maskArray, save_dir) :\n",
    "    '''\n",
    "    Plots post-processed detected Plaques\n",
    "    with the diversity of Colour distingushing\n",
    "    the density of Plaques\n",
    "    \n",
    "    ie. More Diversity of Colour\n",
    "    == More Plaque Count for that certain Plaque type\n",
    "    \n",
    "    Inputs:\n",
    "        maskArray = Numpy Array containing Unique plaque\n",
    "        save_dir  = String for Save Directory\n",
    "    '''\n",
    "    \n",
    "    max_val = np.amax(np.unique(maskArray))\n",
    "#     print(\"Maximum Value = \", max_val)\n",
    "    maskArray = np.asarray(maskArray, dtype=np.float64)\n",
    "    maskArray = np.repeat(maskArray[:,:, np.newaxis], 3, axis=2)\n",
    "\n",
    "    for label in np.unique(maskArray) :\n",
    "\n",
    "        # For label 0, leave as black color (BG)\n",
    "        if label == 0:\n",
    "            continue\n",
    "\n",
    "        idx = np.where(maskArray[:,:,0] == label) \n",
    "\n",
    "        # For label, create HSV space based on unique labels\n",
    "        maskArray[:,:,0].flat[np.ravel_multi_index(idx, maskArray[:,:,0].shape)] = label / max_val\n",
    "        maskArray[:,:,1].flat[np.ravel_multi_index(idx, maskArray[:,:,1].shape)] = label % max_val\n",
    "        maskArray[:,:,2].flat[np.ravel_multi_index(idx, maskArray[:,:,2].shape)] = 1\n",
    "\n",
    "    rgb_maskArray = hsv2rgb(maskArray)\n",
    "    rgb_maskArray = rgb_maskArray * 255\n",
    "    rgb_maskArray = rgb_maskArray.astype(np.uint8) # PIL save only accepts uint8 {0,..,255}\n",
    "    \n",
    "    save_img = Image.fromarray(rgb_maskArray, 'RGB')\n",
    "    save_img.save(save_dir)\n",
    "    print(\"Saved at: \" + save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_blobs(labeled_mask, seg_area) :\n",
    "    \"\"\"\n",
    "    Classifies each certain plaques according to each\n",
    "    Segmentation Area and gives each count\n",
    "    \n",
    "    Input:\n",
    "        labeled_mask (NumPy Array): \n",
    "            contains plaque information \n",
    "            Note: See count_blobs()'s \n",
    "            labeled_mask output for more info\n",
    "        \n",
    "        seg_area (NumPy Array):\n",
    "            contains segmentation information\n",
    "            based on BrainSeg's classification\n",
    "            \n",
    "    Output:\n",
    "        count_dict (Dictionary):\n",
    "            contains number of plaques at each\n",
    "            segmentaion area\n",
    "            \n",
    "        Other Variables:\n",
    "            - Background Count\n",
    "            - WM Count\n",
    "            - GM Count\n",
    "            - Unclassified Count\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0: Background, 1: WM, 2: GM\n",
    "    count_dict = {0: 0, 1: 0, 2: 0, \"uncounted\": 0}\n",
    "    # Loop over unique components\n",
    "    for label in np.unique(labeled_mask) :\n",
    "        if label == 0:\n",
    "            continue\n",
    "            \n",
    "        plaque_loc = np.where(labeled_mask == label)\n",
    "        plaque_area = seg_area[plaque_loc]\n",
    "        indexes, counts = np.unique(plaque_area, return_counts=True)\n",
    "        class_idx = indexes[np.where(counts == np.amax(counts))]\n",
    "        \n",
    "        try:\n",
    "            class_idx = class_idx.item()\n",
    "            count_dict[class_idx] += 1\n",
    "                \n",
    "        except:\n",
    "            count_dict[\"uncounted\"] += 1\n",
    "            \n",
    "    return count_dict, count_dict[0], count_dict[1], count_dict[2], count_dict[\"uncounted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create CSV containing WSI names for\n",
    "# plaque counting at different regions\n",
    "file = pd.DataFrame({\"WSI_ID\": filenames})\n",
    "file.to_csv(CSV_DIR, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using existing CSV\n",
    "file = pd.read_csv(CSV_DIR)\n",
    "filenames = list(file['WSI_ID'])\n",
    "img_class = ['cored', 'diffuse', 'caa']\n",
    "\n",
    "# two hyperparameters (For Plaque-Counting)\n",
    "confidence_thresholds = [0.1, 0.95, 0.9]\n",
    "pixel_thresholds = [100, 1, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [01:40<28:23, 100.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA3777-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2/18 [03:31<28:31, 107.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4077-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 3/18 [04:56<24:07, 96.52s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4092-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 4/18 [05:49<18:33, 79.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4107-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 5/18 [06:35<14:35, 67.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4160-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 6/18 [07:23<12:09, 60.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4195-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 7/18 [09:25<14:48, 80.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4256-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 8/18 [10:54<13:53, 83.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4299-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 9/18 [12:18<12:32, 83.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4391-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 10/18 [13:56<11:45, 88.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4450-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 11/18 [14:03<07:21, 63.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4463-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 12/18 [15:32<07:06, 71.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4471-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 13/18 [16:57<06:16, 75.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4553-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 14/18 [17:22<04:00, 60.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4626-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 15/18 [18:15<02:53, 57.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4672-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 16/18 [19:45<02:15, 67.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4675-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 17/18 [20:08<00:54, 54.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4691-02_AB_cored.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [20:48<00:00, 69.35s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4695-02_AB_cored.png\n",
      "0.1 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1/18 [05:14<1:29:14, 314.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA3777-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2/18 [08:16<1:02:59, 236.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4077-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 3/18 [09:20<39:29, 157.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4092-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 4/18 [12:28<39:35, 169.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4107-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 5/18 [18:11<50:19, 232.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4160-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 6/18 [19:40<36:43, 183.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4195-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 7/18 [25:23<43:10, 235.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4256-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 8/18 [28:06<35:25, 212.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4299-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 9/18 [29:28<25:45, 171.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4391-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 10/18 [32:55<24:19, 182.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4450-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 11/18 [33:01<14:59, 128.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4463-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 12/18 [34:04<10:52, 108.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4471-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 13/18 [34:19<06:41, 80.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4553-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 14/18 [34:25<03:50, 57.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4626-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 15/18 [35:27<02:56, 58.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4672-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 16/18 [36:43<02:08, 64.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4675-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 17/18 [37:52<01:05, 65.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4691-02_AB_diffuse.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [40:03<00:00, 133.54s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4695-02_AB_diffuse.png\n",
      "0.95 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 1/18 [00:15<04:30, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA3777-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 2/18 [00:28<03:42, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4077-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 3/18 [00:39<03:08, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4092-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 4/18 [00:46<02:25, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4107-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 5/18 [00:54<02:03,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4160-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 6/18 [01:06<02:04, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4195-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 7/18 [02:05<04:47, 26.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4256-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 8/18 [02:12<03:20, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4299-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 9/18 [02:21<02:30, 16.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4391-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 10/18 [02:31<01:56, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4450-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 11/18 [02:37<01:23, 11.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4463-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 12/18 [02:53<01:19, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4471-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 13/18 [03:20<01:26, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4553-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 14/18 [03:27<00:57, 14.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4626-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 15/18 [03:32<00:34, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4672-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 16/18 [03:40<00:20, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4675-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 17/18 [03:47<00:09,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4691-02_AB_caa.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [03:58<00:00, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved at: data/outputs/masked_plaque/images/NA4695-02_AB_caa.png\n",
      "0.9 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Post-process Plaque Confidence\n",
    "# and Count Plaques at each region\n",
    "\n",
    "new_file = file\n",
    "for index in [0,1,2]:\n",
    "    preds = np.zeros(len(file))\n",
    "    confidence_threshold = confidence_thresholds[index]\n",
    "    pixel_threshold = pixel_thresholds[index]\n",
    "    \n",
    "    bg = np.zeros(len(file))\n",
    "    wm = np.zeros(len(file))\n",
    "    gm = np.zeros(len(file))\n",
    "    unknowns = np.zeros(len(file))\n",
    "\n",
    "    for i, WSIname in enumerate(tqdm(filenames)):\n",
    "        try:\n",
    "            heatmap_path = HEATMAP_DIR+'new_WSI_heatmap_{}.npy'.format(WSIname)\n",
    "            h = np.load(heatmap_path)\n",
    "\n",
    "        except:\n",
    "            heatmap_path = HEATMAP_DIR+'{}.npy'.format(WSIname)\n",
    "            h = np.load(heatmap_path)\n",
    "            seg_path = POST_NP_DIR+'{}.npy'.format(WSIname)\n",
    "            seg = np.load(seg_path)\n",
    "\n",
    "        mask = h[index] > confidence_threshold\n",
    "        mask = mask.astype(np.float32)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(5,5))\n",
    "\n",
    "        # Apply morphological closing, then opening operations \n",
    "        opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        labels, img_mask, labeled_mask = count_blobs(closing, threshold=pixel_threshold)\n",
    "        counts, bg[i], wm[i], gm[i], unknowns[i] = classify_blobs(labeled_mask, seg)\n",
    "    \n",
    "        save_img = SAVE_IMG_DIR + WSIname \\\n",
    "                    + \"_\" + img_class[index] + \".png\"\n",
    "        save_np = SAVE_NP_DIR + WSIname \\\n",
    "                    + \"_\" + img_class[index] + \".npy\"\n",
    "        np.save(save_np, labeled_mask)\n",
    "        saveUniqueMaskImage(labeled_mask, save_img) # To show Colored Result\n",
    "#         saveMask(img_mask, save_img)  # To show Classification Result\n",
    "        \n",
    "        preds[i] = len(labels)\n",
    "        \n",
    "\n",
    "    print(confidence_threshold, pixel_threshold)\n",
    "\n",
    "    new_file['CNN_{}_count'.format(img_class[index])] = preds\n",
    "    new_file['BG_{}_count'.format(img_class[index])] = bg\n",
    "    new_file['GM_{}_count'.format(img_class[index])] = gm\n",
    "    new_file['WM_{}_count'.format(img_class[index])] = wm\n",
    "    new_file['{}_no-count'.format(img_class[index])] = unknowns\n",
    "    \n",
    "\n",
    "new_file.to_csv(SAVE_DIR+'CNN_vs_CERAD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
